{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8febf8f4",
   "metadata": {},
   "source": [
    "# **XGBoost**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "628267cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import os, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db361f1",
   "metadata": {},
   "source": [
    "### **Carga del *data frame***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a6576d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Falló TSV con engine='c': Error tokenizing data. C error: Expected 21 fields in line 15, saw 42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def load_table(path):\n",
    "    # intento estándar (TSV con engine C)\n",
    "    try:\n",
    "        return pd.read_csv(path, sep='\\t', engine='c', low_memory=False)\n",
    "    except Exception as e1:\n",
    "        print(f\"[1] Falló TSV con engine='c': {e1}\")\n",
    "    # fallback: TSV con engine python (sin low_memory!)\n",
    "    try:\n",
    "        return pd.read_csv(path, sep='\\t', engine='python',\n",
    "                           quoting=csv.QUOTE_NONE,\n",
    "                           on_bad_lines='warn',\n",
    "                           encoding='utf-8')\n",
    "    except Exception as e2:\n",
    "        print(f\"[2] Falló TSV con engine='python': {e2}\")\n",
    "    # último recurso: autodetectar delimitador\n",
    "    with open(path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "        head = ''.join([next(f) for _ in range(10)])\n",
    "    sniff = csv.Sniffer().sniff(head, delimiters=[',','\\t',';'])\n",
    "    delim = sniff.delimiter\n",
    "    print(f\"[3] Sniffer detectó delimitador: {repr(delim)}\")\n",
    "    return pd.read_csv(path, sep=delim, engine='python',\n",
    "                       quoting=csv.QUOTE_NONE,\n",
    "                       on_bad_lines='warn',\n",
    "                       encoding='utf-8')\n",
    "\n",
    "# Parámetros\n",
    "DATA_DIR = '.'\n",
    "SPOTIFY_JSON_DIR = './spotify_api_data'\n",
    "OUT_CSV = 'submission_xgb_formato_clase.csv'\n",
    "SEED = 123\n",
    "\n",
    "train_data = os.path.join(DATA_DIR, 'data', 'train_data.txt')\n",
    "test_data  = os.path.join(DATA_DIR, 'data', 'test_data.txt')\n",
    "\n",
    "train_df = load_table(train_data)\n",
    "test_df  = load_table(test_data)\n",
    "\n",
    "print(train_df.shape, test_df.shape)\n",
    "train_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b8bc56",
   "metadata": {},
   "source": [
    "### **Valores faltantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd84b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_na%</th>\n",
       "      <th>test_na%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>audiobook_chapter_title</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audiobook_chapter_uri</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audiobook_title</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audiobook_uri</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conn_country</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episode_name</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episode_show_name</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incognito_mode</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_addr</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>master_metadata_album_album_name</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>master_metadata_album_artist_name</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>master_metadata_track_name</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offline</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offline_timestamp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platform</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuffle</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spotify_episode_uri</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spotify_track_uri</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   train_na%  test_na%\n",
       "audiobook_chapter_title                  1.0     1.000\n",
       "audiobook_chapter_uri                    1.0     1.000\n",
       "audiobook_title                          1.0     1.000\n",
       "audiobook_uri                            1.0     1.000\n",
       "conn_country                             0.0     0.000\n",
       "episode_name                             1.0     0.997\n",
       "episode_show_name                        1.0     0.997\n",
       "incognito_mode                           0.0     0.000\n",
       "ip_addr                                  0.0     0.000\n",
       "master_metadata_album_album_name         0.0     0.003\n",
       "master_metadata_album_artist_name        0.0     0.003\n",
       "master_metadata_track_name               0.0     0.003\n",
       "offline                                  0.0     0.000\n",
       "offline_timestamp                        0.0     0.000\n",
       "platform                                 0.0     0.000\n",
       "shuffle                                  0.0     0.000\n",
       "spotify_episode_uri                      1.0     0.997\n",
       "spotify_track_uri                        0.0     0.003\n",
       "ts                                       0.0     0.000\n",
       "username                                 0.0     0.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick NA check\n",
    "na_train = train_df.isna().mean().sort_values(ascending=False).head(20)\n",
    "na_test  = test_df.isna().mean().sort_values(ascending=False).head(20)\n",
    "display(pd.DataFrame({'train_na%': na_train, 'test_na%': na_test}).fillna(0).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34b73ac",
   "metadata": {},
   "source": [
    "### **Preparar conjuntos de entrenamiento, validación (*hold-out*) y evaluación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34158f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_data.txt] OK: 911329 | saltadas: 14 | cols: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabit\\AppData\\Local\\Temp\\ipykernel_17944\\1790054341.py:38: DtypeWarning: Columns (8,9,10,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path_out, sep='\\t', engine='c')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_data.txt] OK: 51570 | saltadas: 0 | cols: 21\n",
      "Shapes: (911329, 23) (51570, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>platform</th>\n",
       "      <th>conn_country</th>\n",
       "      <th>ip_addr</th>\n",
       "      <th>master_metadata_track_name</th>\n",
       "      <th>master_metadata_album_artist_name</th>\n",
       "      <th>master_metadata_album_album_name</th>\n",
       "      <th>spotify_track_uri</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>episode_show_name</th>\n",
       "      <th>spotify_episode_uri</th>\n",
       "      <th>audiobook_title</th>\n",
       "      <th>audiobook_uri</th>\n",
       "      <th>audiobook_chapter_uri</th>\n",
       "      <th>audiobook_chapter_title</th>\n",
       "      <th>reason_end</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>offline</th>\n",
       "      <th>offline_timestamp</th>\n",
       "      <th>incognito_mode</th>\n",
       "      <th>username</th>\n",
       "      <th>obs_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-10-30 19:20:00+00:00</td>\n",
       "      <td>Windows 7 (6.1.7601; x86; SP1; S)</td>\n",
       "      <td>AR</td>\n",
       "      <td>6472d74d7192fecaa2744625ea9e29285bde602e641a03...</td>\n",
       "      <td>The Eater Of Dreams</td>\n",
       "      <td>Nine Inch Nails</td>\n",
       "      <td>Hesitation Marks</td>\n",
       "      <td>spotify:track:1IPdwxRUbuNZiRpFN49RQC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fwdbtn</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4324517c6925bba98b4e3a6896d1398fae8f777969e7bc...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-10-30 19:20:00+00:00</td>\n",
       "      <td>Windows 7 (6.1.7601; x86; SP1; S)</td>\n",
       "      <td>AR</td>\n",
       "      <td>6472d74d7192fecaa2744625ea9e29285bde602e641a03...</td>\n",
       "      <td>Copy Of A</td>\n",
       "      <td>Nine Inch Nails</td>\n",
       "      <td>Hesitation Marks</td>\n",
       "      <td>spotify:track:4BFKCEp4gwG3QHNlYodLMy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trackdone</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4324517c6925bba98b4e3a6896d1398fae8f777969e7bc...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-10-30 19:40:00+00:00</td>\n",
       "      <td>Windows 7 (6.1.7601; x86; SP1; S)</td>\n",
       "      <td>AR</td>\n",
       "      <td>6472d74d7192fecaa2744625ea9e29285bde602e641a03...</td>\n",
       "      <td>All Time Low</td>\n",
       "      <td>Nine Inch Nails</td>\n",
       "      <td>Hesitation Marks</td>\n",
       "      <td>spotify:track:7r8raRQN9BxUIs5op8GG8j</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trackdone</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4324517c6925bba98b4e3a6896d1398fae8f777969e7bc...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ts                           platform conn_country  \\\n",
       "0  2013-10-30 19:20:00+00:00  Windows 7 (6.1.7601; x86; SP1; S)           AR   \n",
       "1  2013-10-30 19:20:00+00:00  Windows 7 (6.1.7601; x86; SP1; S)           AR   \n",
       "2  2013-10-30 19:40:00+00:00  Windows 7 (6.1.7601; x86; SP1; S)           AR   \n",
       "\n",
       "                                             ip_addr  \\\n",
       "0  6472d74d7192fecaa2744625ea9e29285bde602e641a03...   \n",
       "1  6472d74d7192fecaa2744625ea9e29285bde602e641a03...   \n",
       "2  6472d74d7192fecaa2744625ea9e29285bde602e641a03...   \n",
       "\n",
       "  master_metadata_track_name master_metadata_album_artist_name  \\\n",
       "0        The Eater Of Dreams                   Nine Inch Nails   \n",
       "1                  Copy Of A                   Nine Inch Nails   \n",
       "2               All Time Low                   Nine Inch Nails   \n",
       "\n",
       "  master_metadata_album_album_name                     spotify_track_uri  \\\n",
       "0                 Hesitation Marks  spotify:track:1IPdwxRUbuNZiRpFN49RQC   \n",
       "1                 Hesitation Marks  spotify:track:4BFKCEp4gwG3QHNlYodLMy   \n",
       "2                 Hesitation Marks  spotify:track:7r8raRQN9BxUIs5op8GG8j   \n",
       "\n",
       "  episode_name episode_show_name spotify_episode_uri  audiobook_title  \\\n",
       "0          NaN               NaN                 NaN              NaN   \n",
       "1          NaN               NaN                 NaN              NaN   \n",
       "2          NaN               NaN                 NaN              NaN   \n",
       "\n",
       "   audiobook_uri  audiobook_chapter_uri  audiobook_chapter_title reason_end  \\\n",
       "0            NaN                    NaN                      NaN     fwdbtn   \n",
       "1            NaN                    NaN                      NaN  trackdone   \n",
       "2            NaN                    NaN                      NaN  trackdone   \n",
       "\n",
       "   shuffle  offline offline_timestamp  incognito_mode  \\\n",
       "0    False    False               NaN           False   \n",
       "1    False    False               NaN           False   \n",
       "2    False    False               NaN           False   \n",
       "\n",
       "                                            username  obs_id  target  \n",
       "0  4324517c6925bba98b4e3a6896d1398fae8f777969e7bc...      16       1  \n",
       "1  4324517c6925bba98b4e3a6896d1398fae8f777969e7bc...      17       0  \n",
       "2  4324517c6925bba98b4e3a6896d1398fae8f777969e7bc...      18       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "CANON = [\n",
    "    \"ts\",\"platform\",\"conn_country\",\"ip_addr\",\n",
    "    \"master_metadata_track_name\",\"master_metadata_album_artist_name\",\"master_metadata_album_album_name\",\n",
    "    \"spotify_track_uri\",\"episode_name\",\"episode_show_name\",\"spotify_episode_uri\",\n",
    "    \"audiobook_title\",\"audiobook_uri\",\"audiobook_chapter_uri\",\"audiobook_chapter_title\",\n",
    "    \"reason_end\",\"shuffle\",\"offline\",\"offline_timestamp\",\"incognito_mode\",\"username\",\"obs_id\"\n",
    "]\n",
    "CANON_TEST = [c for c in CANON if c != \"reason_end\"]\n",
    "\n",
    "def _clean_to_ncols(in_path, out_path, ncols, header_names):\n",
    "    \"\"\"Deja solo filas con exactamente ncols columnas (separadas por TAB)\n",
    "       y escribe header_names como encabezado.\"\"\"\n",
    "    kept = 0; skipped = 0\n",
    "    with open(in_path, 'r', encoding='utf-8', errors='replace') as fin, \\\n",
    "         open(out_path, 'w', encoding='utf-8', newline='') as fout:\n",
    "        fout.write('\\t'.join(header_names) + '\\n')\n",
    "        # saltamos la primera línea original (sea header o no)\n",
    "        first = fin.readline()\n",
    "        for line in fin:\n",
    "            row = line.rstrip('\\n').split('\\t')\n",
    "            if len(row) == ncols:\n",
    "                fout.write('\\t'.join(row) + '\\n'); kept += 1\n",
    "            else:\n",
    "                skipped += 1\n",
    "    return kept, skipped\n",
    "\n",
    "def _load_tsv_fixed(path_in, expect_labels=True):\n",
    "    ncols = 22 if expect_labels else 21\n",
    "    names = CANON if expect_labels else CANON_TEST\n",
    "    path_out = path_in.replace('.txt', f'_clean_{ncols}.tsv')\n",
    "    kept, skipped = _clean_to_ncols(path_in, path_out, ncols, names)\n",
    "    print(f\"[{os.path.basename(path_in)}] OK: {kept} | saltadas: {skipped} | cols: {ncols}\")\n",
    "    df = pd.read_csv(path_out, sep='\\t', engine='c')\n",
    "    # sanity final\n",
    "    assert list(df.columns) == names, \"Columnas inesperadas tras limpieza.\"\n",
    "    return df\n",
    "\n",
    "# rutas base\n",
    "train_path = os.path.join(DATA_DIR, 'data', 'train_data.txt')\n",
    "test_path  = os.path.join(DATA_DIR, 'data', 'test_data.txt')\n",
    "\n",
    "# 1) intentamos cargar con el formato esperado (train=22, test=21)\n",
    "train_df = _load_tsv_fixed(train_path, expect_labels=True)\n",
    "test_df  = _load_tsv_fixed(test_path,  expect_labels=False)\n",
    "\n",
    "# 2) si por algún motivo train NO tiene reason_end, probamos swap automático\n",
    "if 'reason_end' not in train_df.columns and 'reason_end' in test_df.columns:\n",
    "    print(\" Detectado swap train/test. Intercambiando…\")\n",
    "    # recargar al revés\n",
    "    train_df = _load_tsv_fixed(test_path,  expect_labels=True)\n",
    "    test_df  = _load_tsv_fixed(train_path, expect_labels=False)\n",
    "\n",
    "# 3) ahora sí, target\n",
    "if 'reason_end' not in train_df.columns:\n",
    "    raise ValueError(\"No encuentro 'reason_end' en el train tras la limpieza. Verificá que el train sea el de entrenamiento.\")\n",
    "train_df['target'] = (train_df['reason_end'].astype(str).str.strip().str.lower() == 'fwdbtn').astype('int8')\n",
    "\n",
    "print(\"Shapes:\", train_df.shape, test_df.shape)\n",
    "display(train_df.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8261ed",
   "metadata": {},
   "source": [
    "### **XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9abeccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (911329, 10) (51570, 10) (911329,) | cat: 7 num: 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# columnas categóricas y numéricas\n",
    "cat_cols = ['platform','conn_country','ip_addr',\n",
    "            'master_metadata_track_name','master_metadata_album_artist_name',\n",
    "            'master_metadata_album_album_name','username']\n",
    "cat_cols = [c for c in cat_cols if c in train_df.columns]\n",
    "\n",
    "num_cols = ['hour','dayofweek','month','shuffle','offline','incognito_mode',\n",
    "            'has_track','has_episode','has_audiobook',\n",
    "            'epi_duration_ms','epi_explicit','epi_langs_n','epi_release_year']\n",
    "num_cols = [c for c in num_cols if c in train_df.columns]\n",
    "\n",
    "# rellenar NaN en categóricas con un token fijo\n",
    "for c in cat_cols:\n",
    "    train_df[c] = train_df[c].fillna(\"<NA>\")\n",
    "    test_df[c]  = test_df[c].fillna(\"<NA>\")\n",
    "\n",
    "# encoder ordinal\n",
    "enc = OrdinalEncoder(\n",
    "    handle_unknown='use_encoded_value',\n",
    "    unknown_value=-1,\n",
    "    dtype=np.int32\n",
    ")\n",
    "enc.fit(pd.concat([train_df[cat_cols], test_df[cat_cols]], axis=0) if cat_cols else pd.DataFrame())\n",
    "\n",
    "def build_matrix(df: pd.DataFrame):\n",
    "    Xc = enc.transform(df[cat_cols]).astype(np.float32) if cat_cols else np.empty((len(df),0), dtype=np.float32)\n",
    "    Xn = df[num_cols].to_numpy(dtype=np.float32) if num_cols else np.empty((len(df),0), dtype=np.float32)\n",
    "    return np.hstack([Xc, Xn]).astype(np.float32)\n",
    "\n",
    "# features y target\n",
    "X = build_matrix(train_df)\n",
    "Xt = build_matrix(test_df)\n",
    "y = train_df['target'].to_numpy(dtype=np.int32)\n",
    "\n",
    "# grupos (por usuario)\n",
    "groups = train_df['username'].fillna('NA').astype(str).to_numpy()\n",
    "\n",
    "print(\"Shapes:\", X.shape, Xt.shape, y.shape, \"| cat:\", len(cat_cols), \"num:\", len(num_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d1c00",
   "metadata": {},
   "source": [
    "### **Búsqueda de hiperparámetros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f321e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_SEARCH = False\n",
    "\n",
    "if DO_SEARCH:\n",
    "    param_dist = {\n",
    "        'n_estimators': [600, 900, 1200, 1500],\n",
    "        'learning_rate': [0.03, 0.05, 0.07, 0.1],\n",
    "        'max_depth': [4, 6, 8],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "        'reg_lambda': [0.5, 1.0, 2.0],\n",
    "    }\n",
    "    base = XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='auc',\n",
    "        tree_method='hist',\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    search = RandomizedSearchCV(\n",
    "        base, param_distributions=param_dist,\n",
    "        n_iter=12, scoring='roc_auc', cv=3,\n",
    "        random_state=SEED, verbose=1, n_jobs=-1\n",
    "    )\n",
    "    search.fit(X, y)\n",
    "    print(\"Best params:\", search.best_params_)\n",
    "    print(\"Best CV AUC:\", search.best_score_)\n",
    "    xgb = search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef55bd6",
   "metadata": {},
   "source": [
    "### **Conjunto de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb72dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC validación: 0.57519 | best_round=90\n",
      "✅ Submit guardado en: submission_xgb_formato_clase.csv | filas: 51570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_id</th>\n",
       "      <th>pred_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>911345</td>\n",
       "      <td>0.730681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>911346</td>\n",
       "      <td>0.338616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>911347</td>\n",
       "      <td>0.089688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>911348</td>\n",
       "      <td>0.089068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>911349</td>\n",
       "      <td>0.089125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   obs_id  pred_proba\n",
       "0  911345    0.730681\n",
       "1  911346    0.338616\n",
       "2  911347    0.089688\n",
       "3  911348    0.089068\n",
       "4  911349    0.089125"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) split por usuario (hold-out 20%)\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.80, random_state=SEED)\n",
    "tr_idx, va_idx = next(gss.split(X, y, groups=groups))\n",
    "X_tr, y_tr = X[tr_idx], y[tr_idx]\n",
    "X_va, y_va = X[va_idx], y[va_idx]\n",
    "\n",
    "# 2) pesos por desbalance (por si fwdbtn es minoría)\n",
    "pos_ratio = float(y.mean())\n",
    "scale_pos = (1.0 - pos_ratio) / max(pos_ratio, 1e-6)\n",
    "\n",
    "# 3) params XGBoost (baseline sólido)\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"eta\": 0.06,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.9,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"lambda\": 1.0,\n",
    "    \"scale_pos_weight\": scale_pos,\n",
    "    \"seed\": SEED,\n",
    "}\n",
    "\n",
    "# 4) DMatrix + train con early stopping\n",
    "dtr = xgb.DMatrix(X_tr, label=y_tr)\n",
    "dva = xgb.DMatrix(X_va, label=y_va)\n",
    "watchlist = [(dtr, \"train\"), (dva, \"valid\")]\n",
    "\n",
    "bst = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtr,\n",
    "    num_boost_round=1200,\n",
    "    evals=watchlist,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "# 5) AUC validación usando la mejor iteración, compatible 1.x/2.x\n",
    "def _predict_best(bst, dmat):\n",
    "    # xgboost >=2.0: iteration_range\n",
    "    if hasattr(bst, \"best_iteration\") and bst.best_iteration is not None:\n",
    "        return bst.predict(dmat, iteration_range=(0, bst.best_iteration + 1))\n",
    "    # xgboost 1.x: best_ntree_limit\n",
    "    if hasattr(bst, \"best_ntree_limit\") and bst.best_ntree_limit:\n",
    "        return bst.predict(dmat, ntree_limit=bst.best_ntree_limit)\n",
    "    return bst.predict(dmat)\n",
    "\n",
    "val_pred = _predict_best(bst, dva)\n",
    "val_auc = roc_auc_score(y_va, val_pred)\n",
    "best_round = (bst.best_iteration + 1) if hasattr(bst, \"best_iteration\") and bst.best_iteration is not None else getattr(bst, \"best_ntree_limit\", bst.best_score if hasattr(bst, \"best_score\") else 1200)\n",
    "print(f\"AUC validación: {val_auc:.5f} | best_round={best_round}\")\n",
    "\n",
    "# 6) Reentrenar con la mejor cantidad de árboles\n",
    "dfull = xgb.DMatrix(X, label=y)\n",
    "bst_full = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dfull,\n",
    "    num_boost_round=int(best_round) if isinstance(best_round, (int, np.integer)) else 1200,\n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "# 7) Predicción a test + submit\n",
    "dtest = xgb.DMatrix(Xt)\n",
    "test_proba = _predict_best(bst_full, dtest)\n",
    "sub = pd.DataFrame({\"obs_id\": test_df[\"obs_id\"].astype(\"int64\"), \"pred_proba\": test_proba}).sort_values(\"obs_id\")\n",
    "sub.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Submit guardado en: {OUT_CSV} | filas: {len(sub)}\")\n",
    "sub.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
